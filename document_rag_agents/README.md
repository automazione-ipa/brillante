# Document Augmentation RAG Application (autogenerated)

This application implements an enhanced Retrieval-Augmented Generation (RAG) approach using document augmentation via question generation. The overall pipeline involves:

- **Document Processing:** Extracting text from PDF files, chunking the text, and generating questions from each chunk.
- **Embedding Generation & Vector Store:** Creating embeddings for both text chunks and generated questions, and storing them in a vector database.
- **Semantic Search & Response Generation:** Performing semantic search over the vector store, preparing the context, and generating responses using a language model.
- **Evaluation:** Optionally evaluating the generated response against a reference answer.

## Folder structure
Il repository è organizzato secondo la seguente struttura:

    .
    ├── app_evaluate.py            # Entry point for generating augmented responses and evaluating them
    ├── app_rag_pipeline.py        # Entry point for processing documents and building the vector store
    │
    ├── document_rag_agents/       # Core agents and pipelines for the application
    │   ├── base_agents/           # Low-level agents for specific tasks
    │   │   ├── chat_agent.py      # Handles LLM-based chat and response generation
    │   │   ├── docai_agent.py     # (Optional) Additional document AI functions
    │   │   ├── embedding_agent.py # Embedding generation functionalities
    │   │   └── text_chunker.py    # Text chunking functions
    │   │
    │   ├── complex_agents/        # High-level agents that combine base agents
    │   │   ├── rag_pipeline.py            # Pipeline to process document (extract, chunk, question generation, vector store)
    │   │   ├── semantic_search_agent.py   # Semantic search functionalities using vector embeddings
    │   │   └── vector_search_agent.py     # Combines search and context preparation
    │   │
    │   ├── db/                   # Database / storage modules
    │   │   ├── query_data.py      # Handles query and reference data extraction from JSON files
    │   │   └── simple_vector_store.py  # A simple vector store using NumPy
    │   │
    │   └── pipelines/            # Orchestrators for complete workflows
    │       ├── generate_augmented_response.py  # Generates augmented responses with optional evaluation
    │       └── generate_pipeline_v2.py           # Alternative pipeline for generating and evaluating responses
    │
    └── data/                     # Sample data folder
        ├── AI_information.pdf    # PDF file containing the document to process
        └── val.json              # JSON file containing query and ideal answer for evaluation 

## Getting Started

### Prerequisites

- Python 3.7+
- [PyMuPDF](https://pypi.org/project/PyMuPDF/) (`pip install pymupdf`)
- [NumPy](https://numpy.org/) (`pip install numpy`)
- [tqdm](https://tqdm.github.io/) (`pip install tqdm`)
- OpenAI Python Client (ensure you have access to the API key)
- Environment variable `OPENAI_API_KEY` set with your API key

### Installation

1. **Clone the repository:**

   ```bash
   git clone https://github.com/your_username/document-augmentation-rag.git
   cd document-augmentation-rag
   ```

2. **Install dependencies:**

   ```bash
   pip install -r requirements.txt
   ```

3. **Set your API key:**

   Ensure that your `OPENAI_API_KEY` is set in your environment:

   ```bash
   export OPENAI_API_KEY="your_api_key_here"
   ```

### Running the Application

#### 1. Process a Document

Run the RAG pipeline to extract text, generate chunks, augment them with questions, and build the vector store:

```bash
python app_rag_pipeline.py
```

This script processes the PDF file `data/AI_information.pdf` and prints:
- The number of items in the vector store.
- The number of text chunks created.
- The first text chunk for preview.

#### 2. Generate Augmented Response & Evaluation

Run the evaluation pipeline to generate an augmented response from the processed document and optionally evaluate it:

```bash
python app_evaluate.py
```

This script uses the pipeline defined in `document_rag_agents/pipelines/generate_augmented_response.py` to:
- Retrieve the query and reference data from `data/val.json`.
- Perform semantic search over the vector store.
- Generate and print the response.
- Optionally evaluate the response and print the evaluation results.

## Modules Overview

### Base Agents

- **chat_agent.py:** Handles LLM-based chat generation and evaluation.
- **docai_agent.py:** (Optional) Contains additional document processing functionalities.
- **embedding_agent.py:** Manages embedding creation using OpenAI's embedding API.
- **text_chunker.py:** Provides text chunking functionality.

### Complex Agents

- **rag_pipeline.py:** Orchestrates the complete document processing pipeline.
- **semantic_search_agent.py:** Performs semantic search using cosine similarity.
- **vector_search_agent.py:** Combines semantic search with context preparation for generating responses.

### Database (DB)

- **query_data.py:** Retrieves query data and reference answers from JSON files.
- **simple_vector_store.py:** Implements a simple vector store using NumPy arrays.

### Pipelines

- **generate_augmented_response.py:** High-level pipeline that generates augmented responses and optionally evaluates them.
- **generate_pipeline_v2.py:** Alternative generation pipeline with integrated response evaluation.

## Contributing

Contributions are welcome! Please fork the repository and submit a pull request with your improvements.

## License

This project is licensed under the MIT License.

---

*Enjoy building your document augmentation RAG system and happy coding!*
```